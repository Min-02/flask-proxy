from flask import Flask, request, jsonify
from flask_cors import CORS
import pandas as pd
import numpy as np
from urllib.parse import urlencode
from geopy.distance import geodesic
from sklearn.neighbors import BallTree
import importlib.util
import urllib3
import math
import ssl
import json
import joblib
import os

app = Flask(__name__)
CORS(app, resources={r"/api/*": {"origins": "*"}})

@app.route("/api/proxy", methods=["GET"])
def proxy():
    service_key = "rA86OMjx7TmsRL+UAjovPORxHyyDJZxd6dIPJyKlqbPZzNo5fetvxLXhZ/MPki0fWIgUPGXq0thGIvFG5BmTZg=="
    base_url = "https://apis.data.go.kr/B553077/api/open/sdsc2/storeListInRadius"

    params = {
        "serviceKey": service_key,
        "radius": request.args.get("radius"),
        "cx": request.args.get("cx"),
        "cy": request.args.get("cy"),
        "indsLclsCd": "I2",  # ì „ì²´ ìŒì‹ì 
        "indsMclsCd": request.args.get("indsMclsCd"),  # í•„í„°ë§ìš© ì¤‘ë¶„ë¥˜ ì—…ì¢…ì½”ë“œ
        "numOfRows": 100,
        "pageNo": 1,
        "type": "json"
    }

    try:
        ctx = ssl.create_default_context()
        ctx.set_ciphers("DEFAULT:@SECLEVEL=1")

        encoded_params = urlencode(params)
        full_url = f"{base_url}?{encoded_params}"
        print("[ìš”ì²­ URL]", full_url)

        http = urllib3.PoolManager(ssl_context=ctx)
        response = http.request("GET", full_url)

        if response.status != 200:
            return jsonify({"error": "ì™¸ë¶€ API ìš”ì²­ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."}), 500

        data = json.loads(response.data.decode("utf-8"))
        return jsonify(data)

    except Exception as e:
        print("ì˜ˆì™¸ ë°œìƒ:", e)
        return jsonify({"error": str(e)}), 500

@app.route("/api/predict", methods=["POST"])
def predicted_sales():
    # ğŸ“¦ ë³´ì • ë¡œì§ ë¶ˆëŸ¬ì˜¤ê¸°
    spec = importlib.util.spec_from_file_location("bojeong", "ë³´ì •ë¡œì§_ì„œë¹„ìŠ¤êµ¬ì¡°_ì •í•©ë²„ì „.py")
    bojeong = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(bojeong)
    get_sales_distribution_basis = bojeong.get_sales_distribution_basis
    apply_temporal_corrections = bojeong.apply_temporal_corrections

    # ğŸ“‚ ëª¨ë¸ ë° ì…ë ¥ í”¼ì²˜ ì˜ˆì¸¡ê°’ ë¶ˆëŸ¬ì˜¤ê¸°
    model_paths = {
        "í•œì‹ìŒì‹ì ": "0518_model_Korean_Chinese.pkl",
        "ì¤‘ì‹ìŒì‹ì ": "0518_model_Korean_Chinese.pkl",
        "ì»¤í”¼-ìŒë£Œ": "0518_model_Cafe_Beverage.pkl"
    }
    label_encoders = joblib.load("0518_encoders.pkl")
    feature_df = pd.read_csv("2025_input_vector.csv")

    # ğŸ“‚ ë°ì´í„°ì…‹ ë¡œë“œ í•¨ìˆ˜ ì •ì˜
    def load_dataframe(path):
        try:
            return pd.read_csv(path, encoding='cp949')
        except UnicodeDecodeError:
            return pd.read_csv(path, encoding='utf-8-sig')

    # ğŸ“‚ ë°ì´í„° ë¡œë”©
    df = load_dataframe("0510_ê´‘ì§„êµ¬ ìƒê¶Œ, ì§€í•˜ì²  í†µí•© ì™„ì„±ë³¸.csv")
    df_subway = load_dataframe("ê´‘ì§„êµ¬ ì§€í•˜ì²  í‰ê·  ìŠ¹í•˜ì°¨ ì¸ì› ìˆ˜.csv").dropna(subset=["ìœ„ë„", "ê²½ë„"])

    # ğŸ“Œ ê¸°ì¤€ë¶„ê¸° ì¶”ê°€ (ì˜ˆ: 20244)
    df["ê¸°ì¤€ë¶„ê¸°"] = df["ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ"].astype(str).str[:4].astype(int) * 10 + df["ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ"].astype(str).str[-1].astype(int)

    # ğŸ“ BallTree êµ¬ì¶• (ìœ„ì¹˜ ê¸°ë°˜ ìµœê·¼ ìƒê¶Œ íƒìƒ‰ìš©)
    coords_rad = np.radians(df[["ìœ„ë„", "ê²½ë„"]])
    tree = BallTree(coords_rad, metric="haversine")

    # ğŸ”¹ ìœ„ë„/ê²½ë„ ê¸°ì¤€ ê±°ë¦¬ ì´ë™ ë³´ì • í•¨ìˆ˜
    def offset_latlon(lat, lon, dy_m, dx_m):
        delta_lat = dy_m / 111000
        delta_lon = dx_m / (111000 * math.cos(math.radians(lat)))
        return lat + delta_lat, lon + delta_lon

    # ğŸ”¹ ê°€ì¥ ê°€ê¹Œìš´ ì§€í•˜ì² ì—­ ì°¾ê¸°
    def find_nearest_station(lat, lon):
        best_row = df_subway.iloc[((df_subway["ìœ„ë„"] - lat) ** 2 + (df_subway["ê²½ë„"] - lon) ** 2).idxmin()]
        dist = geodesic((lat, lon), (best_row["ìœ„ë„"], best_row["ê²½ë„"])).meters
        name = f"{best_row['ì—­ëª…']} ({best_row['ë…¸ì„ ëª…']})"
        traffic = best_row["ì¼ì¼_í‰ê· _ìŠ¹í•˜ì°¨_ì¸ì›_ìˆ˜"]
        return name, dist, traffic

    # ğŸ”¹ ê°€ì¥ ê°€ê¹Œìš´ ìƒê¶Œ íƒìƒ‰
    def find_nearest_area(lat, lon):
        query_rad = np.radians([[lat, lon]])
        dist, idx = tree.query(query_rad, k=1)
        nearest = df.iloc[idx[0][0]]
        return nearest, dist[0][0] * 6371000

    # ğŸ”¹ ìƒê¶Œ ì½”ë“œë¡œ ì…ë ¥ í”¼ì²˜ ì˜ˆì¸¡ ë²¡í„° ë¶ˆëŸ¬ì˜¤ê¸°
    def load_predicted_vector(area_code: int) -> dict:
        row = feature_df[feature_df["ìƒê¶Œ_ì½”ë“œ"] == area_code]
        if row.empty:
            raise ValueError(f"âŒ ìƒê¶Œ ì½”ë“œ {area_code} ì— í•´ë‹¹í•˜ëŠ” ì˜ˆì¸¡ í”¼ì²˜ ì—†ìŒ")
        return row.iloc[0].to_dict()

    # âœ… íŒŒìƒ í”¼ì²˜ ìƒì„± í•¨ìˆ˜ (ì•ˆì „ ë²„ì „)
    def add_derived_features(df):
        df = df.copy()
        df["ë‚¨ì„±_ë¹„ìœ¨"] = df["ë‚¨ì„±_ìœ ë™ì¸êµ¬_ìˆ˜"] / (df["ì´_ìœ ë™ì¸êµ¬_ìˆ˜"] + 1)
        df["ì—¬ì„±_ë¹„ìœ¨"] = df["ì—¬ì„±_ìœ ë™ì¸êµ¬_ìˆ˜"] / (df["ì´_ìœ ë™ì¸êµ¬_ìˆ˜"] + 1)
        df["ì—°ë ¹ëŒ€_ì¤‘ì‹¬ê°’"] = (
            df["ì—°ë ¹ëŒ€_10_ìœ ë™ì¸êµ¬_ìˆ˜"] * 10 +
            df["ì—°ë ¹ëŒ€_20_ìœ ë™ì¸êµ¬_ìˆ˜"] * 20 +
            df["ì—°ë ¹ëŒ€_30_ìœ ë™ì¸êµ¬_ìˆ˜"] * 30 +
            df["ì—°ë ¹ëŒ€_40_ìœ ë™ì¸êµ¬_ìˆ˜"] * 40 +
            df["ì—°ë ¹ëŒ€_50_ìœ ë™ì¸êµ¬_ìˆ˜"] * 50 +
            df["ì—°ë ¹ëŒ€_60_ì´ìƒ_ìœ ë™ì¸êµ¬_ìˆ˜"] * 65
        ) / (df["ì´_ìœ ë™ì¸êµ¬_ìˆ˜"] + 1)
        df["ìƒì£¼ëŒ€ë¹„_ìœ ë™ë¹„"] = df["ì´_ìœ ë™ì¸êµ¬_ìˆ˜"] / (df["ì´_ìƒì£¼ì¸êµ¬_ìˆ˜"] + 1)
        df["ì§ì¥ëŒ€ë¹„_ìœ ë™ë¹„"] = df["ì´_ìœ ë™ì¸êµ¬_ìˆ˜"] / (df["ì´_ì§ì¥_ì¸êµ¬_ìˆ˜"] + 1)
        if "ìš´ì˜_ì˜ì—…_ê°œì›”_í‰ê· " in df.columns and "ì„œìš¸_ìš´ì˜_ì˜ì—…_ê°œì›”_í‰ê· " in df.columns:
            df["ìƒê¶Œ_vs_ì„œìš¸_ìš´ì˜ì°¨"] = df["ìš´ì˜_ì˜ì—…_ê°œì›”_í‰ê· "] - df["ì„œìš¸_ìš´ì˜_ì˜ì—…_ê°œì›”_í‰ê· "]
        else:
            df["ìƒê¶Œ_vs_ì„œìš¸_ìš´ì˜ì°¨"] = np.nan

        if "íì—…_ì˜ì—…_ê°œì›”_í‰ê· " in df.columns and "ì„œìš¸_íì—…_ì˜ì—…_ê°œì›”_í‰ê· " in df.columns:
            df["ìƒê¶Œ_vs_ì„œìš¸_íì—…ì°¨"] = df["íì—…_ì˜ì—…_ê°œì›”_í‰ê· "] - df["ì„œìš¸_íì—…_ì˜ì—…_ê°œì›”_í‰ê· "]
        else:
            df["ìƒê¶Œ_vs_ì„œìš¸_íì—…ì°¨"] = np.nan
        df["ê²½ìŸ_ë°€ì§‘ë„"] = df["300më‚´_ê²½ìŸ_ì—…ì¢…_ìˆ˜"] / (df["ì´_ìœ ë™ì¸êµ¬_ìˆ˜"] + 1)
        df["ì—­_ì ‘ê·¼ì„±"] = df["ê°€ì¥_ê°€ê¹Œìš´_ì—­_ìŠ¹í•˜ì°¨_ì¸ì›_ìˆ˜"] / (df["ì—­ê¹Œì§€_ê±°ë¦¬_m"] + 1)
        return df

    # ì…ë ¥ëœ ë°ì´í„°
    data = request.get_json()
    lat = float(data["lat"])
    lon = float(data["lon"])
    indsMclsCd = data["indsMclsCd"]

    time_range = data["time_range"]  # ì˜ˆ: "6-14"
    start_time_str, end_time_str = time_range.split("-")
    start_time = int(start_time_str)
    end_time = int(end_time_str)
    selected_days = data["day_of_week"]

    # ì½”ë“œ â†’ ì—…ì¢…ëª… ë§¤í•‘
    industry_code_map = {
        "I212": "ì»¤í”¼-ìŒë£Œ",
        "I201": "í•œì‹ìŒì‹ì ",
        "I202": "ì¤‘ì‹ìŒì‹ì ",
        # í•„ìš” ì‹œ ê³„ì† ì¶”ê°€
    }
    # âœ… ì—…ì¢… ì½”ë“œ â†’ ì—…ì¢…ëª… ë³€í™˜
    category = industry_code_map.get(indsMclsCd)

    print(lat, lon, start_time, end_time, selected_days, category, indsMclsCd)

    try:
        # ğŸ“ ì…ë ¥ ìœ„ì¹˜ ê¸°ì¤€ ìƒê¶Œ/ì§€í•˜ì²  ë¶„ì„
        nearest, _ = find_nearest_area(lat, lon)
        station_name, station_dist, station_traffic = find_nearest_station(lat, lon)

        change_encoder = (
            label_encoders["ìƒê¶Œ_ë³€í™”_ì§€í‘œ_ëª…"]["ì»¤í”¼_ìŒë£Œ"]
            if "ì»¤í”¼" in category else label_encoders["ìƒê¶Œ_ë³€í™”_ì§€í‘œ_ëª…"]["í•œì‹ì¤‘ì‹_í†µí•©"]
        )
        change_encoded = change_encoder.transform([nearest["ìƒê¶Œ_ë³€í™”_ì§€í‘œ_ëª…"]])[0]

        model = joblib.load(model_paths[category])
        df_basis = get_sales_distribution_basis(df, nearest["ìƒê¶Œ_ì½”ë“œ_ëª…"], category)
        df_basis = df_basis.dropna(subset=["ì í¬_ë‹¹_ë§¤ì¶œ_ê¸ˆì•¡"])

        # ğŸ“Œ ì˜ˆì¸¡ ë¶ˆê°€ëŠ¥í•œ ì¡°ê±´ ì²˜ë¦¬
        if len(df_basis) == 0:
            print(f"\nğŸ“ ê°€ì¥ ê°€ê¹Œìš´ ìƒê¶Œ: {nearest['ìƒê¶Œ_ì½”ë“œ_ëª…']}")
            print(f"ğŸ§¾ ì—…ì¢…: {category}")
            print("\nâŒ ì˜ˆì¸¡ ë¶ˆê°€: í•´ë‹¹ ìƒê¶Œ+ì—…ì¢… ì¡°í•©ì— ëŒ€í•œ ë§¤ì¶œ ë°ì´í„°ê°€ ì¡´ì¬í•˜ì§€ ì•Šì•„ ì˜ˆì¸¡í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print("\nğŸ“ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì£¼ë³€ ìœ„ì¹˜ ë¶„ì„ ì¤‘...")
            base_sales = None
            return jsonify({
                "error": "í•´ë‹¹ ìƒê¶Œ+ì—…ì¢… ì¡°í•©ì— ëŒ€í•œ ë§¤ì¶œ ë°ì´í„°ê°€ ì—†ì–´ ì˜ˆì¸¡í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            }), 400

        else:
            if len(df_basis) <= 3:
                print(f"\nğŸ“ ê°€ì¥ ê°€ê¹Œìš´ ìƒê¶Œ: {nearest['ìƒê¶Œ_ì½”ë“œ_ëª…']}")
                print(f"ğŸ§¾ ì—…ì¢…: {category}")
                print("\nâš ï¸ ì°¸ê³ : í•´ë‹¹ ìƒê¶Œ+ì—…ì¢… ì¡°í•©ì€ ë§¤ì¶œ ë°ì´í„°ê°€ 3ê°œ ì´í•˜ë¡œ, ì˜ˆì¸¡ ê²°ê³¼ì˜ ì‹ ë¢°ë„ê°€ ë‚®ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

            # âœ… ì…ë ¥ í”¼ì²˜ êµ¬ì„±
            input_vec = load_predicted_vector(nearest["ìƒê¶Œ_ì½”ë“œ"])
            input_vec["300më‚´_ê²½ìŸ_ì—…ì¢…_ìˆ˜"] = nearest["300më‚´_ê²½ìŸ_ì—…ì¢…_ìˆ˜"]
            input_vec["ì—­ê¹Œì§€_ê±°ë¦¬_m"] = station_dist
            input_vec["ê°€ì¥_ê°€ê¹Œìš´_ì—­_ìŠ¹í•˜ì°¨_ì¸ì›_ìˆ˜"] = station_traffic
            input_vec["ìƒê¶Œ_ë³€í™”_ì§€í‘œ_ëª…"] = int(change_encoded)

            # âœ… ëˆ„ë½ í”¼ì²˜ ë³´ì™„
            needed_cols = [
                "ìš´ì˜_ì˜ì—…_ê°œì›”_í‰ê· ", "íì—…_ì˜ì—…_ê°œì›”_í‰ê· ",
                "ì„œìš¸_ìš´ì˜_ì˜ì—…_ê°œì›”_í‰ê· ", "ì„œìš¸_íì—…_ì˜ì—…_ê°œì›”_í‰ê· "
            ]
            recent_row = df[
                (df["ê¸°ì¤€ë¶„ê¸°"] == 20244) &
                (df["ìƒê¶Œ_ì½”ë“œ"].astype(int) == int(nearest["ìƒê¶Œ_ì½”ë“œ"])) &
                (df["ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ_ëª…"] == category)
                ]
            if not recent_row.empty:
                for col in needed_cols:
                    if col not in input_vec:
                        input_vec[col] = recent_row.iloc[0].get(col, np.nan)
            else:
                for col in needed_cols:
                    input_vec[col] = np.nan

            # âœ… íŒŒìƒ í”¼ì²˜ í¬í•¨ ì…ë ¥ ë°ì´í„°í”„ë ˆì„ êµ¬ì„± ë° ì˜ˆì¸¡
            input_df = pd.DataFrame([input_vec])
            input_df = add_derived_features(input_df)
            input_df = input_df[model.feature_names_in_]

            predicted_sales = model.predict(input_df)[0]
            predicted_sales = apply_temporal_corrections(predicted_sales, df_basis, selected_days, start_time, end_time)
            base_sales = predicted_sales

            base_result = {"lat": lat, "lon": lon, "sales": int(predicted_sales),
                           "ìƒê¶Œëª…": nearest["ìƒê¶Œ_ì½”ë“œ_ëª…"],
                           "ì§€í•˜ì² ì—­": station_name,
                           "ì§€í•˜ì² ì—­ê±°ë¦¬": int(station_dist),
                           "ìŠ¹í•˜ì°¨": int(station_traffic)
                           }

            print(f"\nğŸ“ ê°€ì¥ ê°€ê¹Œìš´ ìƒê¶Œ: {nearest['ìƒê¶Œ_ì½”ë“œ_ëª…']}")
            print(f"ğŸš‡ ê°€ì¥ ê°€ê¹Œìš´ ì§€í•˜ì² ì—­: {station_name} (ê±°ë¦¬: {station_dist:.1f}m, ì¼ì¼ ìŠ¹í•˜ì°¨: {int(station_traffic):,}ëª…)")
            print(f"ğŸ•’ ì˜ì—… ì‹œê°„: {start_time}ì‹œ ~ {end_time}ì‹œ")
            print(f"ğŸ“† ì˜ì—… ìš”ì¼: {', '.join(selected_days)}")
            print(f"ğŸ’° ì˜ˆì¸¡ ì›” ë§¤ì¶œ: ì•½ {int(predicted_sales):,}ì› (ê¸°ì¤€ 100%)")
            print("\nğŸ“ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì£¼ë³€ ìœ„ì¹˜ ë¶„ì„ ì¤‘...")

        results = []

        if base_sales is not None:
            for dy in range(-300, 301, 30):
                for dx in range(-300, 301, 30):
                    adj_lat, adj_lon  = offset_latlon(lat, lon, dy, dx)
                    dist = geodesic((lat, lon), (adj_lat, adj_lon )).meters
                    if dist <= 300:
                        if abs(adj_lat - lat) < 1e-6 and abs(adj_lon - lon) < 1e-6:
                            continue

                        near, _ = find_nearest_area(adj_lat, adj_lon)
                        try:
                            input_vec = load_predicted_vector(near["ìƒê¶Œ_ì½”ë“œ"])
                        except Exception:
                            continue

                        df_basis_near = get_sales_distribution_basis(df, near["ìƒê¶Œ_ì½”ë“œ_ëª…"], category)
                        df_basis_near = df_basis_near.dropna(subset=["ì í¬_ë‹¹_ë§¤ì¶œ_ê¸ˆì•¡"])
                        if len(df_basis_near) < 4:
                            continue

                        stat_name, stat_d, stat_t = find_nearest_station(adj_lat, adj_lon)
                        chg_enc = change_encoder.transform([near["ìƒê¶Œ_ë³€í™”_ì§€í‘œ_ëª…"]])[0]

                        input_vec["ì—­ê¹Œì§€_ê±°ë¦¬_m"] = stat_d
                        input_vec["ê°€ì¥_ê°€ê¹Œìš´_ì—­_ìŠ¹í•˜ì°¨_ì¸ì›_ìˆ˜"] = stat_t
                        input_vec["ìƒê¶Œ_ë³€í™”_ì§€í‘œ_ëª…"] = int(chg_enc)
                        input_vec["300më‚´_ê²½ìŸ_ì—…ì¢…_ìˆ˜"] = near["300më‚´_ê²½ìŸ_ì—…ì¢…_ìˆ˜"]

                        # âœ… ëˆ„ë½ í”¼ì²˜ ë³´ì™„
                        recent_row = df[
                            (df["ê¸°ì¤€ë¶„ê¸°"] == 20244) &
                            (df["ìƒê¶Œ_ì½”ë“œ"].astype(int) == int(near["ìƒê¶Œ_ì½”ë“œ"])) &
                            (df["ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ_ëª…"] == category)
                            ]
                        if not recent_row.empty:
                            for col in needed_cols:
                                if col not in input_vec:
                                    input_vec[col] = recent_row.iloc[0].get(col, np.nan)
                        else:
                            for col in needed_cols:
                                input_vec[col] = np.nan

                        input_df = pd.DataFrame([input_vec])
                        input_df = add_derived_features(input_df)
                        input_df = input_df[model.feature_names_in_]

                        sales = model.predict(input_df)[0]
                        sales = apply_temporal_corrections(sales, df_basis_near, selected_days, start_time, end_time)
                        percent = round(sales / base_sales * 100) if base_sales else None

                        results.append({
                            "lat": adj_lat, "lon": adj_lon, "dist": int(dist), "sales": int(sales),
                            "percent": percent, "ìƒê¶Œëª…": near["ìƒê¶Œ_ì½”ë“œ_ëª…"],
                            "ì§€í•˜ì² ì—­": stat_name, "ì§€í•˜ì² ì—­ê±°ë¦¬": int(stat_d), "ìŠ¹í•˜ì°¨": int(stat_t)
                        })

        # ğŸ”¹ ì¶”ì²œ ê²°ê³¼ ì¶œë ¥
        final_recommendations = []
        ranked_output = []
        if results:
            results_sorted = sorted(results, key=lambda x: -x["sales"])
            rank = 1
            i = 0
            printed_ranks = 0

            while i < len(results_sorted) and printed_ranks < 3:
                current_group = [results_sorted[i]]
                current_sales = results_sorted[i]["sales"]
                i += 1
                while i < len(results_sorted) and abs(results_sorted[i]["sales"] - current_sales) <= 1_000_000:
                    current_group.append(results_sorted[i])
                    i += 1

                group_percent = (
                    f"(ì…ë ¥ ìœ„ì¹˜ ëŒ€ë¹„: {round(current_sales / base_sales * 100)}%)"
                    if base_sales else ""
                )
                title = (
                    f"ğŸ”¸ ê³µë™ {rank}ìœ„ (ì•½ {int(current_sales):,}ì› {group_percent})"
                    if len(current_group) > 1 else
                    f"{rank}ìœ„ (ì•½ {int(current_sales):,}ì› {group_percent})"
                )
                print(f"\n{title}\n")

                group_result = {
                    "ìˆœìœ„": rank,
                    "ë§¤ì¶œ": int(current_sales),
                    "í¼ì„¼íŠ¸": group_percent,
                    "ê³µë™": len(current_group) > 1,
                    "ì¶”ì²œì§€": []
                }

                for loc in current_group[:3]:
                    print(f"ğŸ›ï¸ ìƒê¶Œ: {loc['ìƒê¶Œëª…']}")
                    print(f"ğŸ“ ìœ„ì¹˜: ìœ„ë„ {loc['lat']:.6f}, ê²½ë„ {loc['lon']:.6f}, ê±°ë¦¬ {loc['dist']}m")
                    print(f"ğŸš‡ ì§€í•˜ì² : {loc['ì§€í•˜ì² ì—­']} / ê±°ë¦¬: {loc['ì§€í•˜ì² ì—­ê±°ë¦¬']}m / ìŠ¹í•˜ì°¨: {loc['ìŠ¹í•˜ì°¨']:,}ëª…\n")

                    group_result["ì¶”ì²œì§€"].append({
                        "ìƒê¶Œëª…": loc["ìƒê¶Œëª…"],
                        "lat": loc["lat"],
                        "lon": loc["lon"],
                        "ê±°ë¦¬": loc["dist"],
                        "ì§€í•˜ì² ì—­": loc["ì§€í•˜ì² ì—­"],
                        "ì§€í•˜ì² ì—­ê±°ë¦¬": loc["ì§€í•˜ì² ì—­ê±°ë¦¬"],
                        "ìŠ¹í•˜ì°¨": loc["ìŠ¹í•˜ì°¨"],
                        "ì˜ˆìƒë§¤ì¶œ": loc["sales"]
                    })
                final_recommendations.append(loc)
                ranked_output.append(group_result)
                printed_ranks += 1
                rank += 1
        else:
            print("\nâœ… ì£¼ë³€ì— ë” ë‚˜ì€ ìœ„ì¹˜ëŠ” ì—†ìŠµë‹ˆë‹¤.")

        print("ì…ë ¥ìœ„ì¹˜", base_result)
        print("ì¶”ì²œìœ„ì¹˜", len(final_recommendations), ranked_output)
        print("ì¶”ì²œìˆœìœ„", len(ranked_output), ranked_output)

        return jsonify({
            "ì…ë ¥ìœ„ì¹˜": base_result,
            "ì¶”ì²œìœ„ì¹˜": final_recommendations,
            "ì¶”ì²œìˆœìœ„": ranked_output
            })
    except Exception as e:
        return jsonify({'message': f"âŒ ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"})

if __name__ == "__main__":
    port = int(os.environ.get("PORT", 5000))
    app.run(host="0.0.0.0", port=port, debug=True)
